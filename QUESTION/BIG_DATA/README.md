# Типичные вопросы на собесах

На собесах часто спрашивают одни и те же вопросы. Можно ли выучить ответы и стрелять ими, как из пулемета? Да, конечно. Пока собеседующие не будут нормально готовиться или спрашивать по кейсам, вы будете хакать эту систему.

***В какой-то момент мне начало надоедать, что все спрашивают одно и тоже и начинал уже отвечать на вопросы на скорость...***

- [Задачи с собеседований в моем чате на Boosty](https://boosty.to/halltape_data)

## SQL и базы данных
- Какие бывают виды джоинов логические?
Ответ: inner join, left join rigth join, cross join
- Какие бывают физические джоины?
Ответ: merge join, hash join, Nested Loop
- Как работают физические джоины?
Ответ: Merge join - это метод соединения слиянием, используемый когда обе таблицы достаточно большие и уже есть отсортированные данные по полям (JOIN-ключам участвующим в соединении), например при помощи индексов. Если таблицы не отсортированы заранее, то PostgreSQL выполнит сортировку перед выполнением соединения, что может увеличить затраты. Ключевое отличие от hash join в том, что merge join требует обязательной сортировки данных по JOIN-ключам, когда hash join не требует сортировки вообще. Он просто построит хеш-таблицу и будет использовать ее для поиска совпадений. Так же, про merge join стоит добавить, что он особенно полезен для диапазонных соединений (например, >=, <=), поскольку после сортировки он может эффективно обрабатывать такие условия.
      Hash join - это метод соединения при помощи хэширования, который используется в тех случаях, когда данные, по которым требуется выполнить соединение, не отсортированы. Алгоритм работает так, что сначала выбирается одна из таблиц, обычно меньшая по памяти, и для каждой ее строки создается запись в хеш-таблице. Затем, другая таблица (большая) сканируется, и каждая строка проверяется на сравнение с хеш-таблицей. Если найдено совпадение по нужным значениям, то строки объединяются. Так же, более явно подчеркну деталь, что PostgreSQL выбирает меньшую таблицу для создания хеш-таблицы, чтобы минимизировать использование памяти. Данная хеш-таблица затем используется для быстрого поиска соответствий во второй, более крупной таблицей. Финализируя можно сказать, что hash join чаще всего используется для больших таблиц, когда отсутствуют индексы или когда данные не отсортированы, а условие соединения предполагает точное совпадение (=). Диапазонные соединения, как правило, менее эффективны с hash join.
  Nested Loop - это метод соединения, использующий вложенные циклы, который для каждого значения одной таблицы, ищет соответствующее значение из другой таблицы. Если детальнее, то берется первое значение из первой таблицы и сравнивается последовательно со всеми значениями из второй таблицы, если находится соответствие, то запись включается в финальный набор данных. Когда значение из первой таблицы сравнилось со всеми значениями из второй таблицы, далее берется второе значение из первой маленькой таблицы и снова происходит сравнение со всеми значениями из второй таблицы. Собственно почему и используется название “nested loop” (вложеннеого цикла), т.к. весь процесс происходит до тех пор, пока каждое значение из первой таблицы не будет сравнено с каждым значением из второй таблицы.
- Как удалить дубликаты строк в SQL?
Ответ: 1. Использование DISTINCT для создания новой таблицы
      3. Использование ROW_NUMBER()
        
      
- Какие бывают оконные функции в SQL?
  Агрегатные функции как оконные
Агрегатные функции, такие как SUM(), AVG(), COUNT(), MIN(), MAX(), могут использоваться как оконные функции. Они вычисляют значения для каждой строки на основе окна.
Ранжирующие функции
Эти функции используются для присвоения ранга или номера строки в рамках окна.
ROW_NUMBER() — возвращает уникальный номер строки в рамках окна.
RANK() — возвращает ранг строки с пропусками (если значения совпадают, ранг будет одинаковым, а следующий ранг пропустит).
DENSE_RANK() — возвращает ранг строки без пропусков (если значения совпадают, ранг будет одинаковым, но следующий ранг не пропустит).
NTILE(n) — разбивает строки на n групп и возвращает номер группы для каждой строки
Функции смещения
Эти функции позволяют обращаться к данным из других строк в рамках окна.
LAG() — возвращает значение из строки, которая находится перед текущей.
LEAD() — возвращает значение из строки, которая находится после текущей.
FIRST_VALUE() — возвращает значение из первой строки в окне.
LAST_VALUE() — возвращает значение из последней строки в окне.
- Как найти медиану в таблице?
  В современных СУБД можно использовать оконные функции, такие как ROW_NUMBER(), COUNT(), и PERCENTILE_CONT()

## Модели данных и нормализация

- Что такое нормализация данных?
Нормализация данных — это процесс организации структуры базы данных таким образом, чтобы минимизировать избыточность данных, улучшить целостность данных и упростить выполнение запросов. Нормализация достигается путем разбиения таблиц на более мелкие и логически связанные таблицы, а также установления связей между ними с помощью первичных и внешних ключей.
Нормализация основывается на теории нормальных форм, которые представляют собой набор правил для проектирования базы данных. Каждая нормальная форма (НФ) имеет свои требования, и выполнение этих требований помогает устранить определенные типы аномалий данных.
Основные цели нормализации:
Устранение избыточности данных: Данные не должны дублироваться в разных таблицах.
Обеспечение целостности данных: Данные должны быть согласованными и непротиворечивыми.
Упрощение поддержки базы данных: Легче вносить изменения и обновлять данные.
Улучшение производительности запросов: Оптимизированная структура базы данных может ускорить выполнение запросов.
1. Первая нормальная форма (1НФ)
Каждая таблица должна иметь уникальный идентификатор (первичный ключ).
Все значения в столбцах должны быть атомарными (неделимыми), то есть не должны содержать множественных значений или повторяющихся групп.
2. Вторая нормальная форма (2НФ)
Таблица должна находиться в 1НФ.
Все неключевые столбцы должны зависеть от всего первичного ключа, а не от его части.
3. Третья нормальная форма (3НФ)
Таблица должна находиться в 2НФ.
Все неключевые столбцы должны зависеть только от первичного ключа, а не от других неключевых столбцов.

- Какие бывают модели данных?
  Модели данных — это способы организации и структурирования данных в базе данных. Они определяют, как данные будут храниться, обрабатываться и взаимодействовать друг с другом. Существует несколько основных моделей данных, каждая из которых подходит для решения определенных задач. Рассмотрим основные из них.
1. Иерархическая модель данных
Иерархическая модель представляет данные в виде древовидной структуры, где каждый узел (элемент) имеет одного родителя и несколько дочерних элементов. Эта модель была популярна в ранних СУБД, таких как IBM IMS.
Особенности:
Данные организованы в виде дерева.
Каждый узел (кроме корневого) имеет только одного родителя.
Подходит для данных с четкой иерархией (например, структура организации).
Преимущества:
Простота и высокая производительность для иерархических данных.
Легкость навигации от родителя к дочерним элементам.
Недостатки:
Сложность работы с данными, не имеющими иерархической структуры.
Ограниченная гибкость.
2. Сетевая модель данных
Сетевая модель является расширением иерархической модели. В ней каждый узел может иметь несколько родителей, что позволяет представлять более сложные связи между данными.
Особенности:
Данные организованы в виде графа.
Узлы могут иметь несколько родителей.
Подходит для сложных взаимосвязей.
Преимущества:
Гибкость в представлении сложных связей.
Эффективность для задач с множественными связями.
Недостатки:
Сложность проектирования и поддержки.
Ограниченная популярность в современных СУБД.
3. Реляционная модель данных
Реляционная модель является наиболее распространенной в современных базах данных. Данные организованы в виде таблиц (отношений), где строки представляют записи, а столбцы — атрибуты.
Особенности:
Данные хранятся в таблицах.
Связи между таблицами устанавливаются с помощью ключей (первичных и внешних).
Поддерживает SQL для работы с данными.
Преимущества:
Гибкость и простота использования.
Поддержка сложных запросов с помощью SQL.
Высокая популярность и широкий выбор СУБД (MySQL, PostgreSQL, Oracle и др.).
Недостатки:
Может быть менее эффективной для работы с большими объемами неструктурированных данных.
4. Объектно-ориентированная модель данных
Объектно-ориентированная модель представляет данные в виде объектов, аналогично объектно-ориентированному программированию. Каждый объект содержит данные и методы для работы с ними.
Особенности:
Данные и методы хранятся вместе.
Поддерживает наследование, инкапсуляцию и полиморфизм.
Подходит для сложных данных, таких как мультимедиа.
Преимущества:
Естественное представление сложных данных.
Поддержка объектно-ориентированных принципов.
Недостатки:
Сложность реализации и поддержки.
Ограниченная популярность в СУБД.
5. Объектно-реляционная модель данных
Эта модель сочетает в себе черты реляционной и объектно-ориентированной моделей. Она позволяет хранить данные в таблицах, но также поддерживает объекты, наследование и другие объектно-ориентированные концепции.
Особенности:
Поддерживает таблицы и объекты.
Расширяет SQL для работы с объектами.
Используется в PostgreSQL, Oracle и других СУБД.
Преимущества:
Гибкость и поддержка сложных данных.
Совместимость с реляционными СУБД.
Недостатки:
Сложность проектирования и использования.
6. Документно-ориентированная модель данных
Эта модель используется в NoSQL базах данных, таких как MongoDB. Данные хранятся в виде документов (например, JSON или XML), которые могут иметь вложенную структуру.
Особенности:
Данные хранятся в виде документов.
Подходит для неструктурированных или полуструктурированных данных.
Высокая гибкость.
Преимущества:
Гибкость и простота работы с неструктурированными данными.
Высокая производительность для определенных задач.
Недостатки:
Ограниченная поддержка сложных запросов.
Не подходит для задач, требующих строгой структуры данных.
7. Ключ-значение (Key-Value)
Модель "ключ-значение" используется в NoSQL базах данных, таких как Redis. Данные хранятся в виде пар "ключ-значение", где ключ — это уникальный идентификатор, а значение — данные.
Особенности:
Простая структура данных.
Высокая производительность для операций чтения/записи.
Подходит для кэширования и хранения настроек.
Преимущества:
Высокая скорость работы.
Простота использования.
Недостатки:
Ограниченная функциональность для сложных запросов.
8. Графовая модель данных
Графовая модель используется для представления данных в виде графов, состоящих из узлов и ребер. Подходит для задач, где важны связи между объектами (например, социальные сети, рекомендательные системы).
Особенности:
Данные представлены в виде узлов и ребер.
Подходит для анализа сложных связей.
Используется в базах данных, таких как Neo4j.
Преимущества:
Эффективность для задач с большим количеством связей.
Удобство для анализа графов.
Недостатки:
Сложность для задач, не связанных с анализом связей.
Итог
Каждая модель данных имеет свои преимущества и недостатки, и выбор модели зависит от конкретных задач:
Реляционная модель подходит для большинства традиционных приложений.
NoSQL модели (документная, ключ-значение, графовая) используются для работы с большими объемами неструктурированных данных или сложными связями.
Иерархическая и сетевая модели применяются в специализированных системах.
Правильный выбор модели данных помогает оптимизировать производительность, упростить разработку и обеспечить целостность данных.
достатки:
Может быть менее эффективной для работы с большими объемами неструктурированных данных.


- Что такое Data Vault? 
- Что такое DWH по Инмону и Кимбалу?

## Потоковая и пакетная обработка данных

- Что такое потоковая обработка данных и пакетная обработка данных?
  Потоковая и пакетная обработка данных — это два основных подхода к обработке данных, которые используются в зависимости от требований к скорости, объему и характеру данных. Они применяются в различных сценариях, таких как аналитика, машинное обучение, мониторинг и другие задачи.
1. Пакетная обработка данных (Batch Processing)
Пакетная обработка данных предполагает обработку большого объема данных, собранных за определенный период времени, как единого пакета (batch). Данные накапливаются, а затем обрабатываются в одном или нескольких пакетах.
Особенности:
Данные обрабатываются группами (пакетами).
Обработка происходит с задержкой (не в реальном времени).
Подходит для задач, где не требуется мгновенный результат.
Примеры использования:
Генерация ежедневных отчетов.
Обработка данных в хранилищах данных (Data Warehouses).
Обучение моделей машинного обучения на исторических данных.
Преимущества:
Эффективна для обработки больших объемов данных.
Проще в реализации и управлении.
Оптимизация ресурсов (например, выполнение задач в нерабочее время).
Недостатки:
Задержка в получении результатов.
Не подходит для задач, требующих мгновенной реакции.
2. Потоковая обработка данных (Stream Processing)
Потоковая обработка данных предполагает обработку данных в реальном времени по мере их поступления. Данные обрабатываются непрерывно, и результаты могут быть доступны мгновенно.
Особенности:
Данные обрабатываются по мере поступления.
Результаты доступны в реальном времени.
Подходит для задач, требующих мгновенной реакции.
Примеры использования:
Мониторинг систем в реальном времени (например, обнаружение аномалий).
Обработка данных с IoT-устройств (датчиков, сенсоров).
Рекомендательные системы в реальном времени.
Обработка финансовых транзакций (например, обнаружение мошенничества).
Преимущества:
Мгновенная обработка данных.
Подходит для задач, требующих быстрой реакции.
Возможность обработки бесконечных потоков данных.
Недостатки:
Сложнее в реализации и управлении.
Требует больше ресурсов для обработки в реальном времени.

## ClickHouse
- Как работает ClickHouse?
ClickHouse — это высокопроизводительная колоночная СУБД, разработанная для аналитики и обработки больших объемов данных. Она оптимизирована для выполнения сложных аналитических запросов в реальном времени. Основные принципы работы ClickHouse включают колоночное хранение данных, векторные вычисления, параллельную обработку и эффективное использование ресурсов.
Основные принципы работы ClickHouse
1. Колоночное хранение данных
В отличие от традиционных строковых СУБД, ClickHouse хранит данные в колоночном формате. Это означает, что значения каждого столбца хранятся отдельно, а не в виде строк.
Преимущества:
Эффективное сжатие данных (похожие значения в столбце сжимаются лучше).
Уменьшение объема данных, читаемых с диска (только нужные столбцы).
Высокая производительность для агрегаций и аналитических запросов.
Пример:
id	name	age
1	Alice	25
2	Bob	30
3	Carol	28
В колоночном формате данные хранятся так:
id: [1, 2, 3]
name: ["Alice", "Bob", "Carol"]
age: [25, 30, 28]
2. Векторные вычисления
ClickHouse обрабатывает данные не по одной строке, а блоками (векторами), что позволяет эффективно использовать CPU и кэш процессора.
Преимущества:
Уменьшение накладных расходов на обработку каждой строки.
Высокая скорость выполнения запросов.
3. Параллельная обработка
ClickHouse использует многопоточность и распределенные вычисления для обработки данных:
Запросы выполняются параллельно на нескольких ядрах CPU.
Данные могут быть распределены между несколькими узлами кластера.
Преимущества:
Масштабируемость для больших объемов данных.
Высокая производительность за счет использования всех доступных ресурсов.
4. Эффективное использование индексов
ClickHouse использует первичные и вторичные индексы для ускорения запросов:
Первичный ключ: Определяет порядок данных на диске.
Вторичные индексы: Позволяют быстро находить данные по определенным условиям.
Пример:
sql
Copy
CREATE TABLE my_table (
    id UInt32,
    timestamp DateTime,
    value Float64
) ENGINE = MergeTree()
ORDER BY (id, timestamp);
Здесь ORDER BY (id, timestamp) определяет первичный ключ.
5. Сжатие данных
ClickHouse использует эффективные алгоритмы сжатия (например, LZ4, ZSTD) для уменьшения объема хранимых данных.
Преимущества:
Экономия места на диске.
Уменьшение времени чтения данных.
6. Распределенные вычисления
ClickHouse поддерживает распределенные таблицы, которые позволяют хранить данные на нескольких узлах кластера и выполнять запросы параллельно.
Пример:
sql
Copy
CREATE TABLE my_distributed_table (
    id UInt32,
    value String
) ENGINE = Distributed('my_cluster', 'default', 'my_local_table', rand());
Здесь данные распределяются между узлами кластера my_cluster.
7. Поддержка различных движков таблиц
ClickHouse предоставляет множество движков таблиц, каждый из которых оптимизирован для определенных сценариев использования:
MergeTree: Для аналитики и больших объемов данных.
Log: Для простых сценариев.
Memory: Для временных данных.
Distributed: Для кластеров.
Kafka: Для потоковой обработки.
Как ClickHouse обрабатывает запросы
Парсинг запроса:
ClickHouse анализирует SQL-запрос и строит план выполнения.
Чтение данных:
Данные читаются с диска в виде блоков (векторов).
Используются индексы для ускорения поиска.
Фильтрация и агрегация:
Данные фильтруются и агрегируются в оперативной памяти.
Используются векторные вычисления для повышения производительности.
Возврат результата:
Результат возвращается клиенту в виде таблицы.
Пример работы ClickHouse
Создание таблицы
sql
Copy
CREATE TABLE my_table (
    id UInt32,
    timestamp DateTime,
    value Float64
) ENGINE = MergeTree()
ORDER BY (id, timestamp);
Вставка данных
sql
Copy
INSERT INTO my_table VALUES
(1, '2023-10-01 12:00:00', 100.5),
(2, '2023-10-01 12:01:00', 200.3),
(3, '2023-10-01 12:02:00', 150.7);
Выполнение запроса
sql
Copy
SELECT
    toStartOfHour(timestamp) AS hour,
    avg(value) AS avg_value
FROM my_table
GROUP BY hour;
Результат
hour	avg_value
2023-10-01 12:00:00	150.5
Преимущества ClickHouse
Высокая производительность: Оптимизирован для аналитических запросов.
Масштабируемость: Поддерживает распределенные вычисления.
Эффективное сжатие: Уменьшает объем хранимых данных.
Гибкость: Поддерживает множество движков таблиц и форматов данных.
Недостатки ClickHouse
Не подходит для OLTP: ClickHouse оптимизирован для аналитики, а не для транзакций.
Сложность настройки: Требует глубокого понимания для оптимальной настройки.
Ограниченная поддержка обновлений: Некоторые движки таблиц не поддерживают обновления данных.
Итог
ClickHouse — это мощный инструмент для аналитики и обработки больших объемов данных. Его колоночное хранение, векторные вычисления и поддержка распределенных вычислений делают его идеальным выбором для задач, требующих высокой производительности и масштабируемости. Однако он не подходит для транзакционных задач (OLTP) и требует тщательной настройки для достижения максимальной эффективности.

- Что такое колоночная база данных, в чем ее преимущества и недостатки?
- Отличия OLAP vs OLTP 
- Основные движки ClickHouse
  ClickHouse — это высокопроизводительная колоночная СУБД, разработанная для аналитики и обработки больших объемов данных. Одной из ключевых особенностей ClickHouse является поддержка различных движков таблиц (table engines), которые определяют, как данные хранятся, обрабатываются и запрашиваются. Каждый движок оптимизирован для определенных сценариев использования.
Основные движки таблиц в ClickHouse
1. MergeTree
Семейство движков MergeTree является наиболее популярным и мощным в ClickHouse. Оно предназначено для хранения больших объемов данных с поддержкой эффективных запросов.
Особенности:
Поддержка индексов (первичный ключ, вторичные индексы).
Возможность партиционирования данных.
Поддержка репликации (с использованием ReplicatedMergeTree).
Высокая производительность для аналитических запросов.
Разновидности MergeTree:
ReplicatedMergeTree: Добавляет поддержку репликации данных между узлами кластера.
SummingMergeTree: Автоматически суммирует значения указанных столбцов при слиянии данных.
AggregatingMergeTree: Хранит агрегированные данные (например, результаты GROUP BY).
CollapsingMergeTree: Подходит для данных, которые могут "схлопываться" (например, обновляемые записи).
VersionedCollapsingMergeTree: Улучшенная версия CollapsingMergeTree с поддержкой версий.
GraphiteMergeTree: Оптимизирован для хранения данных метрик (например, для Graphite).
2. Log
Движки семейства Log предназначены для простых сценариев, где данные записываются один раз и редко изменяются.
Особенности:
Данные хранятся в виде файлов (по одному файлу на таблицу).
Поддержка только добавления данных (не поддерживает удаление или обновление).
Низкая производительность для больших объемов данных.
Разновидности Log:
TinyLog: Подходит для небольших таблиц (хранит данные в одном файле).
Log: Подходит для таблиц среднего размера (хранит данные в нескольких файлах).
3. Memory
Движок Memory хранит данные в оперативной памяти. Подходит для временных данных или тестирования.
Особенности:
Данные хранятся только в оперативной памяти.
Высокая скорость работы.
Данные теряются при перезапуске сервера.
4. Null
Движок Null не хранит данные, но позволяет выполнять запросы. Подходит для тестирования или перенаправления данных.
Особенности:
Данные не сохраняются.
Подходит для тестирования или перенаправления данных в другие таблицы.
5. Distributed
Движок Distributed позволяет распределять данные и запросы между несколькими узлами кластера.
Особенности:
Данные хранятся на нескольких узлах.
Запросы автоматически распределяются между узлами.
Подходит для горизонтального масштабирования.
6. Kafka
Движок Kafka позволяет интегрировать ClickHouse с Apache Kafka для потоковой обработки данных.
Особенности:
Автоматически читает данные из Kafka.
Поддерживает потоковую обработку.
Подходит для интеграции с системами реального времени.
7. MaterializedView
Движок MaterializedView позволяет создавать материализованные представления, которые автоматически обновляются при изменении исходных данных.
Особенности:
Данные автоматически обновляются.
Подходит для предварительных вычислений и агрегаций.
8. File
Движок File позволяет работать с данными, хранящимися в файлах (например, CSV, JSON).
Особенности:
Данные хранятся в файлах.
Подходит для импорта/экспорта данных.
9. URL
Движок URL позволяет работать с данными, доступными по HTTP/HTTPS.
Особенности:
Данные загружаются по URL.
Подходит для работы с внешними источниками данных.
Итог
ClickHouse предоставляет множество движков таблиц, каждый из которых оптимизирован для определенных сценариев использования:
MergeTree — для аналитики и больших объемов данных.
Log — для простых сценариев.
Memory — для временных данных.
Distributed — для кластеров.
Kafka — для потоковой обработки.
MaterializedView — для материализованных представлений.
Выбор движка зависит от требований к данным, производительности и сценариев использования.

## Python
- Какие бывают магические функции в Python?
- Что такое декораторы в Python?
- Что такое try except else finally
- Чем отличается итератор от генератора? 
```python
# Что выведет print(a)?
a = [1,2,3]
b = a
b.append(4)
```
- Какие типы данных в Python являются изменяемыми и неизменяемыми? 
- Как работает память в питоне?
- Как работает сборщик мусора в python?
- Написать сортировка пузырьком, быструю сортировку, сортировку слиянием
- Можно ли в словарь в key записать изменяемый тип? Почему?

## Apache Spark
- Почему нельзя использовать Pandas для больших данных, а нужно использовать Spark?
- Минимальное параллелизм в Spark и что это такое?
- Что такое RDD в Spark?
- Что такое Dataset и чем отличается от dataframe и RDD?  
- Какие виды кэширования существуют в Spark и чем они отличаются?
- Что такое persist в Spark и какие storage levels существуют?
- Чем отличается repartition от coalesce в Spark?
- Что делает YARN и зачем он нужен?
- Какие настройки Spark applications вы используете?
- Сколько гигабайт памяти выделяется на каждую задачу в Spark?
- Что такое spill в Spark?
- Что такое broadcast join в Spark и как его настроить?
- Что такое ленивые вычисления в Spark? 
- Что такое Adaptive query execution?

## Apache Airflow
- Сколько типов сервисов в Docker при разворачивании Airflow? 
- Чем отличатеся Celery Executor local executor
- Какая база данных используется в Airflow?
- Можно ли передавать данные по XCOM?

## HDFS
- Что такое HDFS блоки и какие у них есть минусы?
- Как бороться с маленькими файлами в HDFS? Переполнение NameNode


